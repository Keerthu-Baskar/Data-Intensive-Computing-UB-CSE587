# Data-Intensive-Computing-UB-CSE587
UB CSE 587

# LAB1: Data collection and exploratory data analysis

This lab consists of two activities,
1. learning from existing data explorations. Working on data analysis related to socially relevant current topic ("flu"). Exploring the real flu data, replicate in R and learn from the analysis performed by experts in Center for Disease Control (CDC)
2. Collect data by querying Twitter REST API. Extract data using APIs and OAuth keys. Process data using twitteR library package of R, visualize geo spatial information extracted from the tweets using geo-map libraries of R like ggplot2, ggmap supported by Google map API

Result: Compare CDC flu map with my own home-brewed flu map of USA derived from twitter data that I obtained. Created documentation by updating the data-twitter-R-analysis to twitteR vignette

# LAB2: Data aggregation, big data analysis and visualization

In this lab, I have expanded my skills in data exploration developed in lab1, and enhanced them by adding big data analytics and visualization skills.

This lab has 3 parts,
1. Data aggregation - data aggregation (topic: sports) from more than one source (Twitter, New York Times, Common Crawl) using APIs provided by the business
2. Big Data Analysis - Applying classical big data analytics method of MapReduce to unstructured data by storing the data collected on WORM infrastructure Hadoop (algorithms such as word count, word occurrence and n-grams)
3. Visualization - Building a visualization data product using "wordcloud" in tableau. created a responsive web interface for visualizing the outcome of my analysis

Result: Compared the outcome of same analysis for all three sources of data

# LAB3: Data analysis using Apache Spark

In this lab, I have explored processing graph data using spark. I have written an appropriate problem statement for spark by studying the literature. ifentifying a use case and provided details like answering a request for proposal. Provided an executive summary of why, what, when and how spark can be used in solving the problem
